{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of sarsa.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm6vKQSPecUi"
      },
      "source": [
        "## On-policy learning and SARSA\n",
        "\n",
        "_This notebook builds upon `qlearning.ipynb`, or to be exact your implementation of QLearningAgent._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyy5Di5KecUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b261a3-73d3-4547-a418-09c5815bc083"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrrJSXhlecUq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8t2h3yqecUr"
      },
      "source": [
        "You can copy your `QLearningAgent` implementation from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ctUwfUIecUr"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        value=max(self.get_qvalue(state,action) for action in (possible_actions))\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        qvalue=(1-learning_rate)*self.get_qvalue(state,action)+learning_rate*(reward+gamma*(self.get_value(next_state)))\n",
        "\n",
        "        self.set_qvalue(state, action,qvalue )\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        action_dict={action:self.get_qvalue(state,action) for action in (possible_actions)}\n",
        "        best_action=sorted(action_dict,key=lambda x:action_dict[x],reverse=True)[0]\n",
        "\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.getPolicy).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "        exploration=random.random()\n",
        "        if exploration<epsilon:\n",
        "          chosen_action=np.random.choice(possible_actions)\n",
        "        else:\n",
        "          chosen_action=self.get_best_action(state)\n",
        "\n",
        "        return chosen_action"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohCWDqYhecUu"
      },
      "source": [
        "Now we gonna implement Expected Value SARSA on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwMS2xEcecUw"
      },
      "source": [
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        state_value = 0\n",
        "        for action in possible_actions:\n",
        "            if action == self.get_best_action(state):\n",
        "                state_value += ((1-epsilon)+epsilon/len(possible_actions))*self.get_qvalue(state,action)\n",
        "            else:\n",
        "                state_value += epsilon/len(possible_actions)*self.get_qvalue(state,action)\n",
        "\n",
        "        return state_value"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtxTJmVhecUx"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png width=600>\n",
        "<center><i>image by cs188</i></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6tgGM0LecUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47f05e0-4aa1-4ddb-9637-65fcf02eeeb2"
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsMufhdiecUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d523f830-5c59-409e-eba4-5021eb997828"
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlUbaAL5ecU0"
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0RSyU4eecU1"
      },
      "source": [
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPHJRnFGecU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "9aeaa419-0606-4478-a3c5-018ca91c4380"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EVSARSA mean reward = -26.77\n",
            "QLEARNING mean reward = -76.36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_sO_25secU2"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z23gZt31ecU2"
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKTjqDhAecU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d510cada-c44f-4f86-f2de-3585f92d0e8b"
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q-Learning\n",
            " >  v  v  v  v  >  v  >  v  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  ^  ^  ^  ^  ^  ^  ^  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_YLVx88ecU7"
      },
      "source": [
        "### Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrL4W2uRecU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb1e136d-fcc2-4a59-b318-9f6065460703"
      },
      "source": [
        "from submit import submit_sarsa\n",
        "submit_sarsa(rewards_ql, rewards_sarsa, 'siddhy20@iitk.ac.in', 'o12aJHgPj3QX9nRH')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKmwreyDecU8"
      },
      "source": [
        "### More\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    }
  ]
}